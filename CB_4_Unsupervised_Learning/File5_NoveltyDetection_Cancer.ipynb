{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module Ready!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "''' Junhong Kim\n",
    "Ph.D. Student in Industrial Management Engineering\n",
    "Korea University, Seoul, Republic of Korea\n",
    "Mobile Phone +82 10 3099 3004\n",
    "E-mail    junhongkim@korea.ac.kr\n",
    "Data Science and Business Analytics Lab\n",
    "LinkedIn https://www.linkedin.com/in/charcoalgrey/\n",
    "Lab Homepage http://dsba.korea.ac.kr'''\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import mixture\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Module Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 파일을 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root_Directory = os.path.join(os.getcwd(),\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_Data = np.array(pd.read_csv(os.path.join(Root_Directory,\"Cancer_TR.csv\")))\n",
    "VL_Data = np.array(pd.read_csv(os.path.join(Root_Directory,\"Cancer_VL.csv\")))\n",
    "TE_Data = np.array(pd.read_csv(os.path.join(Root_Directory,\"Cancer_TE.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape is :  (230, 31)\n",
      "Validation dataset shape is :  (140, 31)\n",
      "Test dataset shape is :  (71, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset shape is : \",np.shape(TR_Data))\n",
    "print(\"Validation dataset shape is : \",np.shape(VL_Data))\n",
    "print(\"Test dataset shape is : \",np.shape(TE_Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Normalization 해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_Input = TR_Data[:,1:]\n",
    "VL_Input = VL_Data[:,1:]\n",
    "TE_Input = TE_Data[:,1:]\n",
    "VL_Target = VL_Data[:,:1]\n",
    "TE_Target = TE_Data[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TR_Input :  (230, 30)\n",
      "VL_Input :  (140, 30)\n",
      "TE_Input :  (71, 30)\n",
      "VL_Target :  (140, 1)\n",
      "TE_Target :  (71, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"TR_Input : \",np.shape(TR_Input))\n",
    "print(\"VL_Input : \",np.shape(VL_Input))\n",
    "print(\"TE_Input : \",np.shape(TE_Input))\n",
    "print(\"VL_Target : \",np.shape(VL_Target))\n",
    "print(\"TE_Target : \",np.shape(TE_Target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] Training dataset 기준으로 Normalization 해준다, Test시에서는 TR,VL기준으로 Normalization 해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_Mean = np.mean(TR_Input,0)\n",
    "TR_Std = np.std(TR_Input,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TR_Input = (TR_Input-TR_Mean)/TR_Std\n",
    "N_VL_Input = (VL_Input-TR_Mean)/TR_Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_VL_Mean = np.mean(np.vstack((TR_Input,VL_Input)),0)\n",
    "TR_VL_Std = np.std(np.vstack((TR_Input,VL_Input)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2_TR_Input = (np.vstack((TR_Input,VL_Input))-TR_VL_Mean)/TR_VL_Std\n",
    "N2_TE_Input = (TE_Input-TR_VL_Mean)/TR_VL_Std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] 각 모델들을 학습 시켜서 Validation dataset에서 최적의 조건을 찾는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4-1] Single Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우시안 분포 추정 함수\n",
    "def estimateGaussian(dataset):\n",
    "    mu = np.mean(dataset, axis=0)\n",
    "    sigma = np.cov(dataset.T)\n",
    "    return mu, sigma\n",
    "    \n",
    "# 다변량 가우시안에서 pdf를 리턴하는 함수\n",
    "def multivariateGaussian(dataset,mu,sigma):\n",
    "    p = multivariate_normal(mean=mu, cov=sigma)\n",
    "    return p.pdf(dataset)\n",
    "\n",
    "# Validiation dataset을 통해 가장 좋은 epsilon(임계치) 탐색\n",
    "def selectThresholdByCV(probs,gt):  \n",
    "    \n",
    "    best_epsilon = 0\n",
    "    best_f1 = 0\n",
    "    f = 0\n",
    "    stepsize = (max(probs) - min(probs)) / 1000;\n",
    "    epsilons = np.arange(min(probs),max(probs),stepsize)\n",
    "    for epsilon in np.nditer(epsilons):\n",
    "        predictions = (probs < epsilon) \n",
    "        f = f1_score(gt, predictions,average='binary')\n",
    "        if f > best_f1:\n",
    "            best_f1 = f\n",
    "            best_epsilon = epsilon\n",
    "    \n",
    "    return best_f1, best_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = estimateGaussian(N_TR_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multivariateGaussian(N_TR_Input,mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8944723618090452 0.38963552265976753\n"
     ]
    }
   ],
   "source": [
    "#selecting optimal value of epsilon using validation dataset\n",
    "p_cv = multivariateGaussian(N_VL_Input,mu,sigma)\n",
    "fscore, ep = selectThresholdByCV(p_cv,VL_Target[:,0])\n",
    "print(fscore, ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 데이터에 적용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = estimateGaussian(N2_TR_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_Guass_TE = multivariateGaussian(N2_TE_Input,mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting outlier datapoints \n",
    "outliers_Gauss = (p_Guass_TE < ep)+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826086956521738"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(TE_Target, outliers_Gauss,average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4-2] Mixture of Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=500,\n",
       "        means_init=None, n_components=15, n_init=1, precisions_init=None,\n",
       "        random_state=15, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import mixture\n",
    "GMM5 = mixture.GaussianMixture(n_components=5,covariance_type='diag',random_state=15,max_iter=500)\n",
    "GMM10 = mixture.GaussianMixture(n_components=10,covariance_type='diag',random_state=15,max_iter=500)\n",
    "GMM15 = mixture.GaussianMixture(n_components=15,covariance_type='diag',random_state=15,max_iter=500)\n",
    "GMM5.fit(N_TR_Input)\n",
    "GMM10.fit(N_TR_Input)\n",
    "GMM15.fit(N_TR_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation을 통해 가장 좋은 epsilon(임계치) 탐색\n",
    "def selectThresholdByGMM(NL,gt):\n",
    "    best_epsilon = 0\n",
    "    best_f1 = 0\n",
    "    f = 0\n",
    "    stepsize = (max(NL) - min(NL)) / 1000;\n",
    "    epsilons = np.arange(min(NL)+0.001,max(NL),stepsize)\n",
    "    for epsilon in np.nditer(epsilons):\n",
    "        predictions = (NL > epsilon) \n",
    "        f = f1_score(gt, predictions,average='binary')\n",
    "        if f > best_f1:\n",
    "            best_f1 = f\n",
    "            best_epsilon = epsilon    \n",
    "    return best_f1, best_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMM5_Score = -GMM5.score_samples(N_VL_Input) \n",
    "GMM10_Score = -GMM10.score_samples(N_VL_Input) \n",
    "GMM15_Score = -GMM15.score_samples(N_VL_Input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore_GMM5, ep_GMM5 = selectThresholdByGMM(GMM5_Score,VL_Target[:,0])\n",
    "fscore_GMM10, ep_GMM10 = selectThresholdByGMM(GMM10_Score,VL_Target[:,0])\n",
    "fscore_GMM15, ep_GMM15 = selectThresholdByGMM(GMM15_Score,VL_Target[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM 5 F-score :  0.9263157894736842\n",
      "GMM 10 F-score :  0.9263157894736842\n",
      "GMM 15 F-score :  0.9101123595505618\n"
     ]
    }
   ],
   "source": [
    "print(\"GMM 5 F-score : \",fscore_GMM5)\n",
    "print(\"GMM 10 F-score : \",fscore_GMM10)\n",
    "print(\"GMM 15 F-score : \",fscore_GMM15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 데이터에 적용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMM_TE = mixture.GaussianMixture(n_components=5,covariance_type='diag',random_state=15,max_iter=500)\n",
    "GMM_TE.fit(N2_TR_Input)\n",
    "GMM_TE_Score = -GMM_TE.score_samples(N2_TE_Input) \n",
    "outliers_GMM = (GMM_TE_Score > ep_GMM5)+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804878048780488"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(TE_Target, outliers_GMM,average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4-3] Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='old', bootstrap=False, contamination='legacy',\n",
       "        max_features=1.0, max_samples='auto', n_estimators=200,\n",
       "        n_jobs=None, random_state=15, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_50 = IsolationForest(n_estimators=50,random_state=15)\n",
    "iforest_100 = IsolationForest(n_estimators=100,random_state=15)\n",
    "iforest_150 = IsolationForest(n_estimators=150,random_state=15)\n",
    "iforest_200 = IsolationForest(n_estimators=200,random_state=15)\n",
    "iforest_50.fit(N_TR_Input)\n",
    "iforest_100.fit(N_TR_Input)\n",
    "iforest_150.fit(N_TR_Input)\n",
    "iforest_200.fit(N_TR_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_score_Valid_50 = iforest_50.decision_function(N_VL_Input)\n",
    "anomaly_score_Valid_100 = iforest_100.decision_function(N_VL_Input)\n",
    "anomaly_score_Valid_150 = iforest_150.decision_function(N_VL_Input)\n",
    "anomaly_score_Valid_200 = iforest_200.decision_function(N_VL_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set을 통해 가장 좋은 epsilon(임계치) 탐색\n",
    "def selectThresholdByIF(NL,gt):\n",
    "    best_epsilon = 0\n",
    "    best_f1 = 0\n",
    "    f = 0\n",
    "    stepsize = (max(NL) - min(NL)) / 1000;\n",
    "    epsilons = np.arange(min(NL)+0.001,max(NL),stepsize)\n",
    "    for epsilon in np.nditer(epsilons):\n",
    "        predictions = (NL < epsilon) \n",
    "        f = f1_score(gt, predictions,average='binary')\n",
    "        if f > best_f1:\n",
    "            best_f1 = f\n",
    "            best_epsilon = epsilon    \n",
    "    return best_f1, best_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore_50, threshold_50 = selectThresholdByIF(anomaly_score_Valid_50,VL_Target[:,0])\n",
    "fscore_100, threshold_100 = selectThresholdByIF(anomaly_score_Valid_100,VL_Target[:,0])\n",
    "fscore_150, threshold_150 = selectThresholdByIF(anomaly_score_Valid_150,VL_Target[:,0])\n",
    "fscore_200, threshold_200 = selectThresholdByIF(anomaly_score_Valid_200,VL_Target[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF 50 F-score :  0.8972972972972973\n",
      "IF 100 F-score :  0.9090909090909091\n",
      "IF 150 F-score :  0.9081081081081082\n",
      "IF 200 F-score :  0.9071038251366121\n"
     ]
    }
   ],
   "source": [
    "print(\"IF 50 F-score : \",fscore_50)\n",
    "print(\"IF 100 F-score : \",fscore_100)\n",
    "print(\"IF 150 F-score : \",fscore_150)\n",
    "print(\"IF 200 F-score : \",fscore_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 데이터에 적용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_100.fit(N2_TR_Input)\n",
    "anomaly_score_Valid_100 = iforest_100.decision_function(N2_TE_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting outlier datapoints \n",
    "outliers_IsolationForest = (anomaly_score_Valid_100 < threshold_100)+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(TE_Target, outliers_IsolationForest,average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4-4] Local outlier factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalOutlierFactor(algorithm='auto', contamination='legacy', leaf_size=30,\n",
       "          metric='minkowski', metric_params=None, n_jobs=None,\n",
       "          n_neighbors=50, novelty=True, p=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoF_10 = LocalOutlierFactor(n_neighbors=10,novelty=True)\n",
    "LoF_30 = LocalOutlierFactor(n_neighbors=30,novelty=True)\n",
    "LoF_40 = LocalOutlierFactor(n_neighbors=40,novelty=True)\n",
    "LoF_50 = LocalOutlierFactor(n_neighbors=50,novelty=True)\n",
    "LoF_10.fit(N_TR_Input)\n",
    "LoF_30.fit(N_TR_Input)\n",
    "LoF_40.fit(N_TR_Input)\n",
    "LoF_50.fit(N_TR_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoF_10_Score = LoF_10.decision_function(N_VL_Input) \n",
    "LoF_30_Score = LoF_30.decision_function(N_VL_Input) \n",
    "LoF_40_Score = LoF_40.decision_function(N_VL_Input) \n",
    "LoF_50_Score = LoF_50.decision_function(N_VL_Input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set을 통해 가장 좋은 epsilon(임계치) 탐색\n",
    "def selectThresholdByLoF(NL,gt):\n",
    "    best_epsilon = 0\n",
    "    best_f1 = 0\n",
    "    f = 0\n",
    "    stepsize = (max(NL) - min(NL)) / 1000;\n",
    "    epsilons = np.arange(min(NL)+0.001,max(NL),stepsize)\n",
    "    for epsilon in np.nditer(epsilons):\n",
    "        predictions = (NL < epsilon) \n",
    "        f = f1_score(gt, predictions,average='binary')\n",
    "        if f > best_f1:\n",
    "            best_f1 = f\n",
    "            best_epsilon = epsilon    \n",
    "    return best_f1, best_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore_LoF_10, threshold_LoF_10 = selectThresholdByLoF(LoF_10_Score,VL_Target[:,0])\n",
    "fscore_LoF_30, threshold_LoF_30 = selectThresholdByLoF(LoF_30_Score,VL_Target[:,0])\n",
    "fscore_LoF_40, threshold_LoF_40 = selectThresholdByLoF(LoF_40_Score,VL_Target[:,0])\n",
    "fscore_LoF_50, threshold_LoF_50 = selectThresholdByLoF(LoF_50_Score,VL_Target[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoF 10 F-score :  0.8021978021978022\n",
      "LoF 30 F-score :  0.9297297297297298\n",
      "LoF 40 F-score :  0.93048128342246\n",
      "LoF 50 F-score :  0.93048128342246\n"
     ]
    }
   ],
   "source": [
    "print(\"LoF 10 F-score : \",fscore_LoF_10)\n",
    "print(\"LoF 30 F-score : \",fscore_LoF_30)\n",
    "print(\"LoF 40 F-score : \",fscore_LoF_40)\n",
    "print(\"LoF 50 F-score : \",fscore_LoF_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 데이터에 적용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoF_Test = LocalOutlierFactor(n_neighbors=40,novelty=True)\n",
    "LoF_Test.fit(N2_TR_Input)\n",
    "LoF_Test_Score = LoF_40.decision_function(N2_TE_Input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting outlier datapoints \n",
    "outliers_LoF = (LoF_Test_Score < threshold_LoF_40)+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(TE_Target, outliers_LoF,average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] 모델 별 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Real Value ##\n",
    "# TE_Target\n",
    "\n",
    "## Single Gaussian ##\n",
    "# p_Guass_TE\n",
    "# outliers_Gauss\n",
    "\n",
    "## Gaussian mixture ##\n",
    "# GMM_TE_Score\n",
    "# outliers_GMM\n",
    "\n",
    "## Isolation Forest ##\n",
    "# anomaly_score_Valid_100\n",
    "# outliers_IsolationForest\n",
    "\n",
    "## Local outlier factor ##\n",
    "# LoF_Test_Score\n",
    "# outliers_LoF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표를 위한 함수를 생성한다.\n",
    "def Valid_Index(Data,NAME):\n",
    "    Accuracy = (Data[0,0]+Data[1,1])/np.sum(Data)\n",
    "    TPR = Data[1,1]/np.sum(Data[1,:])\n",
    "    TNR = Data[0,0]/np.sum(Data[0,:])\n",
    "    Precision = Data[1,1]/np.sum(Data[:,1])\n",
    "    BCR = np.sqrt(TPR*TNR)\n",
    "    F1 = (2*TPR*Precision)/(TPR+Precision)\n",
    "    TMP=pd.DataFrame({'Model' : NAME,\n",
    "                  'Accuracy' : [Accuracy],\n",
    "                  'TPR': [TPR],\n",
    "                  'TNR': [TNR],\n",
    "                  'Precision': [Precision],\n",
    "                  'BCR': [BCR],\n",
    "                  'F1': [F1]})\n",
    "    Results=TMP[['Model','Accuracy','F1','BCR','Precision','TPR','TNR']]\n",
    "    return(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>BCR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.891133</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Single_Gauss</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.871105</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.843137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianMixture</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.849452</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LocalOutlierFactor</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.822478</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy        F1       BCR  Precision   TPR       TNR\n",
       "0     IsolationForest  0.887324  0.818182  0.891133   0.750000  0.90  0.882353\n",
       "0        Single_Gauss  0.859155  0.782609  0.871105   0.692308  0.90  0.843137\n",
       "0     GaussianMixture  0.873239  0.780488  0.849452   0.761905  0.80  0.901961\n",
       "0  LocalOutlierFactor  0.859155  0.750000  0.822478   0.750000  0.75  0.901961"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_Results = Valid_Index(confusion_matrix(TE_Target,outliers_Gauss),\"Single_Gauss\").append([\n",
    "Valid_Index(confusion_matrix(TE_Target,outliers_GMM),\"GaussianMixture\"),\n",
    "Valid_Index(confusion_matrix(TE_Target,outliers_IsolationForest),\"IsolationForest\"),\n",
    "Valid_Index(confusion_matrix(TE_Target,outliers_LoF),\"LocalOutlierFactor\")])\n",
    "\n",
    "Total_Results = Total_Results.sort_values(by=['F1'],ascending=False)\n",
    "pd.DataFrame(Total_Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss AUROC :  0.931\n",
      "GMM AUROC :  0.945\n",
      "IF AUROC :  0.953\n",
      "LoF AUROC :  0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print( \"Gauss AUROC : \",np.round(roc_auc_score(TE_Target, -p_Guass_TE),3))\n",
    "print( \"GMM AUROC : \",np.round(roc_auc_score(TE_Target, GMM_TE_Score),3))\n",
    "print( \"IF AUROC : \",np.round(roc_auc_score(TE_Target, -anomaly_score_Valid_100),3))\n",
    "print( \"LoF AUROC : \",np.round(roc_auc_score(TE_Target, -LoF_Test_Score),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "END3",
   "language": "python",
   "name": "lab7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
