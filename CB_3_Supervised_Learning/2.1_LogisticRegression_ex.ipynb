{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 머신러닝 알고리즘 및 평가\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "# 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(___________)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "dat = pd.read_csv('./data/classification_parkinsons.csv')\n",
    "\n",
    "# 데이터 확인해보기 상위 10개를 통해서\n",
    "'''\n",
    "print(___________)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 형태 확인해보기\n",
    "'''\n",
    "dat.____\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1974f164179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 의미없는 변수 제거: name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdat_processing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdat_processing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dat' is not defined"
     ]
    }
   ],
   "source": [
    "# 의미없는 변수 제거: name\n",
    "\n",
    "\n",
    "# name 변수 제거하기\n",
    "dat_processing = dat._____(['name'], axis=1, inplace=False)\n",
    "\n",
    "print(dat_processing.columns)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "dat_processing_norm = preprocessing.minmax_scale(dat_processing)\n",
    "dat_processed = pd.DataFrame(dat_processing_norm)\n",
    "dat_processed.columns = dat_processing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_processed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    const  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0     1.0     0.184308      0.112592      0.054815        0.195680   \n",
      "1     1.0     0.198327      0.094930      0.278323        0.254130   \n",
      "2     1.0     0.165039      0.059128      0.265288        0.280178   \n",
      "3     1.0     0.165004      0.072927      0.264200        0.263342   \n",
      "4     1.0     0.161150      0.080909      0.260107        0.354511   \n",
      "5     1.0     0.187568      0.059232      0.278139        0.254130   \n",
      "6     1.0     0.185909      0.071647      0.284086        0.052414   \n",
      "7     1.0     0.110606      0.023873      0.223606        0.038755   \n",
      "8     1.0     0.043063      0.061082      0.151289        0.121665   \n",
      "9     1.0     0.039139      0.036658      0.148249        0.115629   \n",
      "10    1.0     0.000000      0.020607      0.107062        0.107052   \n",
      "11    1.0     0.020789      0.028019      0.119843        0.118170   \n",
      "12    1.0     0.282892      0.117826      0.378827        0.039708   \n",
      "13    1.0     0.295974      0.157167      0.063790        0.070521   \n",
      "14    1.0     0.375568      0.124846      0.059645        0.040025   \n",
      "15    1.0     0.313404      0.235382      0.101805        0.063850   \n",
      "16    1.0     0.325169      0.504433      0.099531        0.119441   \n",
      "17    1.0     0.468324      0.265442      0.058304        0.174714   \n",
      "18    1.0     0.376738      0.150411      0.018118        0.182338   \n",
      "19    1.0     0.396293      0.178109      0.445300        0.190597   \n",
      "\n",
      "    MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer    ...     \\\n",
      "0           0.249012  0.145472  0.247588    0.145288      0.312215    ...      \n",
      "1           0.288538  0.191233  0.323687    0.191042      0.472887    ...      \n",
      "2           0.328063  0.229287  0.369239    0.229411      0.390634    ...      \n",
      "3           0.328063  0.209056  0.324759    0.208862      0.414278    ...      \n",
      "4           0.407115  0.282755  0.437299    0.282870      0.499452    ...      \n",
      "5           0.288538  0.190270  0.352626    0.190079      0.342067    ...      \n",
      "6           0.090909  0.041908  0.058950    0.042061      0.059704    ...      \n",
      "7           0.090909  0.036609  0.048232    0.036442      0.055961    ...      \n",
      "8           0.209486  0.108382  0.128617    0.108525      0.103980    ...      \n",
      "9           0.209486  0.096339  0.128617    0.096163      0.171992    ...      \n",
      "10          0.209486  0.089595  0.127546    0.089742      0.108545    ...      \n",
      "11          0.209486  0.102601  0.130761    0.102745      0.164141    ...      \n",
      "12          0.051383  0.024085  0.032690    0.024241      0.027844    ...      \n",
      "13          0.090909  0.046724  0.062165    0.046878      0.062808    ...      \n",
      "14          0.051383  0.025530  0.030547    0.025686      0.079788    ...      \n",
      "15          0.090909  0.042871  0.059486    0.042864      0.050119    ...      \n",
      "16          0.130435  0.068882  0.107181    0.068711      0.099781    ...      \n",
      "17          0.130435  0.104046  0.158092    0.104190      0.216633    ...      \n",
      "18          0.169960  0.142582  0.182208    0.142559      0.416560    ...      \n",
      "19          0.169960  0.146435  0.164523    0.146412      0.277615    ...      \n",
      "\n",
      "    Shimmer:DDA       NHR       HNR  status      RPDE       DFA   spread1  \\\n",
      "0      0.332584  0.068307  0.511745     1.0  0.369155  0.960148  0.569875   \n",
      "1      0.516048  0.059331  0.432577     1.0  0.470830  0.977024  0.703277   \n",
      "2      0.443317  0.039596  0.496220     1.0  0.404416  1.000000  0.636745   \n",
      "3      0.475478  0.040997  0.495936     1.0  0.416255  0.975885  0.695627   \n",
      "4      0.584542  0.054174  0.455499     1.0  0.375159  0.992813  0.762472   \n",
      "5      0.360829  0.036827  0.525766     1.0  0.370978  0.999128  0.672961   \n",
      "6      0.062460  0.017252  0.668333     1.0  0.792079  0.756277  0.421385   \n",
      "7      0.072089  0.008881  0.749858     1.0  0.888630  0.752890  0.324968   \n",
      "8      0.119014  0.031989  0.543404     1.0  0.837604  0.794025  0.445910   \n",
      "9      0.190012  0.030461  0.545436     1.0  0.677741  0.893130  0.533923   \n",
      "10     0.120234  0.035045  0.515200     1.0  0.827305  0.804260  0.490913   \n",
      "11     0.186674  0.034249  0.527229     1.0  0.762563  0.869453  0.543261   \n",
      "12     0.038773  0.016424  0.701536     1.0  0.476059  0.289093  0.256346   \n",
      "13     0.052638  0.031066  0.668455     1.0  0.405048  0.364736  0.416703   \n",
      "14     0.117281  0.017315  0.669796     1.0  0.509171  0.317702  0.336269   \n",
      "15     0.061112  0.024636  0.680078     1.0  0.721810  0.334506  0.474578   \n",
      "16     0.099114  0.057103  0.564578     1.0  0.725207  0.280511  0.456512   \n",
      "17     0.189883  0.090843  0.485044     1.0  0.873881  0.124041  0.910135   \n",
      "18     0.388304  0.098514  0.359221     1.0  0.953724  0.578412  0.726078   \n",
      "19     0.243934  0.105039  0.354060     1.0  0.916942  0.445400  0.616624   \n",
      "\n",
      "     spread2        D2       PPE  \n",
      "0   0.585765  0.390661  0.497310  \n",
      "1   0.741337  0.473145  0.671326  \n",
      "2   0.686371  0.408819  0.596682  \n",
      "3   0.738089  0.436977  0.671949  \n",
      "4   0.513798  0.404336  0.757611  \n",
      "5   0.659218  0.339999  0.648753  \n",
      "6   0.565955  0.191959  0.346328  \n",
      "7   0.399458  0.285340  0.246912  \n",
      "8   0.723731  0.400034  0.387368  \n",
      "9   0.719740  0.449094  0.469780  \n",
      "10  0.866077  0.437760  0.424998  \n",
      "11  0.804315  0.542376  0.479243  \n",
      "12  0.329880  0.274923  0.194630  \n",
      "13  0.559893  0.487633  0.321750  \n",
      "14  0.444328  0.312443  0.260053  \n",
      "15  0.459033  0.348000  0.393618  \n",
      "16  0.525619  0.374227  0.359600  \n",
      "17  0.963606  0.704746  0.799972  \n",
      "18  0.791492  0.749921  0.689459  \n",
      "19  0.751661  0.637666  0.574888  \n",
      "\n",
      "[20 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# 상수항 추가 : sm.add_constant()\n",
    "'''\n",
    "dat_processed = sm._______(dat_processed, has_constant='add')\n",
    "print(dat_processed.head(20))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dat_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f63353d558f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 전체 데이터 변수 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dat_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 변수 확인\n",
    "print(dat_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['D2', 'DFA', 'HNR', 'Jitter:DDP', 'MDVP:APQ', 'MDVP:Fhi(Hz)',\n",
       "       'MDVP:Flo(Hz)', 'MDVP:Fo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Jitter(Abs)',\n",
       "       'MDVP:PPQ', 'MDVP:RAP', 'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'NHR',\n",
       "       'PPE', 'RPDE', 'Shimmer:APQ3', 'Shimmer:APQ5', 'Shimmer:DDA', 'const',\n",
       "       'spread1', 'spread2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target 변수: 'status'를 제외한 데이터 학습데이터 구성하기\n",
    "dat_processed.columns.difference([\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D2',\n",
       " 'DFA',\n",
       " 'HNR',\n",
       " 'Jitter:DDP',\n",
       " 'MDVP:APQ',\n",
       " 'MDVP:Fhi(Hz)',\n",
       " 'MDVP:Flo(Hz)',\n",
       " 'MDVP:Fo(Hz)',\n",
       " 'MDVP:Jitter(%)',\n",
       " 'MDVP:Jitter(Abs)',\n",
       " 'MDVP:PPQ',\n",
       " 'MDVP:RAP',\n",
       " 'MDVP:Shimmer',\n",
       " 'MDVP:Shimmer(dB)',\n",
       " 'NHR',\n",
       " 'PPE',\n",
       " 'RPDE',\n",
       " 'Shimmer:APQ3',\n",
       " 'Shimmer:APQ5',\n",
       " 'Shimmer:DDA',\n",
       " 'const',\n",
       " 'spread1',\n",
       " 'spread2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = list(dat_processed.columns.difference([\"status\"]))\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat_processed[feature_columns]\n",
    "y = dat_processed['status'] # 질환여부: 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 23) (20, 23) (175,) (20,)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split 함수를 이용하여 학습데이터와 검증데이터로 9:1로 나누어 데이터를 구분해보자.\n",
    "'''\n",
    "train_x, test_x, train_y, test_y = '__________'(X, y, stratify=y, test_size='___', random_state=2017010500)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const               float64\n",
       "MDVP:Fo(Hz)         float64\n",
       "MDVP:Fhi(Hz)        float64\n",
       "MDVP:Flo(Hz)        float64\n",
       "MDVP:Jitter(%)      float64\n",
       "MDVP:Jitter(Abs)    float64\n",
       "MDVP:RAP            float64\n",
       "MDVP:PPQ            float64\n",
       "Jitter:DDP          float64\n",
       "MDVP:Shimmer        float64\n",
       "MDVP:Shimmer(dB)    float64\n",
       "Shimmer:APQ3        float64\n",
       "Shimmer:APQ5        float64\n",
       "MDVP:APQ            float64\n",
       "Shimmer:DDA         float64\n",
       "NHR                 float64\n",
       "HNR                 float64\n",
       "status              float64\n",
       "RPDE                float64\n",
       "DFA                 float64\n",
       "spread1             float64\n",
       "spread2             float64\n",
       "D2                  float64\n",
       "PPE                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dat_processed.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178    1.0\n",
       " 89     1.0\n",
       " 126    1.0\n",
       " 8      1.0\n",
       " 193    0.0\n",
       " 174    0.0\n",
       " 186    0.0\n",
       " 92     1.0\n",
       " 37     1.0\n",
       " 47     0.0\n",
       " 75     1.0\n",
       " 135    1.0\n",
       " 73     1.0\n",
       " 177    1.0\n",
       " 127    1.0\n",
       " 147    1.0\n",
       " 84     1.0\n",
       " 81     1.0\n",
       " 59     1.0\n",
       " 42     0.0\n",
       " 88     1.0\n",
       " 52     0.0\n",
       " 32     0.0\n",
       " 111    1.0\n",
       " 189    0.0\n",
       " 106    1.0\n",
       " 160    1.0\n",
       " 114    1.0\n",
       " 18     1.0\n",
       " 134    1.0\n",
       "       ... \n",
       " 10     1.0\n",
       " 97     1.0\n",
       " 93     1.0\n",
       " 60     0.0\n",
       " 159    1.0\n",
       " 118    1.0\n",
       " 132    1.0\n",
       " 120    1.0\n",
       " 149    1.0\n",
       " 98     1.0\n",
       " 112    1.0\n",
       " 121    1.0\n",
       " 194    0.0\n",
       " 16     1.0\n",
       " 17     1.0\n",
       " 161    1.0\n",
       " 155    1.0\n",
       " 46     0.0\n",
       " 49     0.0\n",
       " 168    0.0\n",
       " 53     0.0\n",
       " 71     1.0\n",
       " 35     0.0\n",
       " 55     1.0\n",
       " 133    1.0\n",
       " 96     1.0\n",
       " 166    0.0\n",
       " 158    1.0\n",
       " 151    1.0\n",
       " 0      1.0\n",
       " Name: status, Length: 175, dtype: float64,\n",
       "            D2       DFA       HNR  Jitter:DDP  MDVP:APQ  MDVP:Fhi(Hz)  \\\n",
       " 178  0.368467  0.749886  0.649069    0.040456  0.045180      0.114749   \n",
       " 89   1.000000  0.682231  0.139194    0.155402  0.209511      0.252682   \n",
       " 126  0.177061  0.653223  0.395716    0.109006  0.117926      0.194113   \n",
       " 8    0.400034  0.794025  0.543404    0.108525  0.076422      0.061082   \n",
       " 193  0.318222  0.277579  0.429936    0.145288  0.066544      0.601807   \n",
       " 174  0.200038  0.725879  0.691051    0.052015  0.045869      0.086390   \n",
       " 186  0.328600  0.371991  0.630619    0.089581  0.059116      1.000000   \n",
       " 92   0.409743  0.638319  0.420182    0.087655  0.178574      0.128283   \n",
       " 37   0.495243  0.834020  0.670975    0.066142  0.059116      0.170364   \n",
       " 47   0.269288  0.242711  0.746322    0.011559  0.010797      0.325264   \n",
       " 75   0.195209  0.928006  0.680972    0.100658  0.076269      0.041777   \n",
       " 135  0.537623  0.527497  0.376575    0.084604  0.198867      0.051984   \n",
       " 73   0.224845  0.857549  0.639559    0.096484  0.094724      0.992831   \n",
       " 177  0.456644  0.683948  0.638462    0.032429  0.039130      0.179754   \n",
       " 127  0.254845  0.648120  0.401894    0.144485  0.121143      0.197640   \n",
       " 147  0.764759  0.775647  0.240836    0.375983  0.431886      0.234073   \n",
       " 84   0.745602  0.618726  0.221572    0.168566  0.213722      0.211101   \n",
       " 81   0.360025  0.814582  0.455905    0.173222  0.112643      0.011370   \n",
       " 59   0.181685  0.968559  0.537227    0.147054  0.137836      0.345324   \n",
       " 42   0.441997  0.318279  0.580956    0.048643  0.031702      0.296357   \n",
       " 88   0.704583  0.675900  0.255954    0.081233  0.312658      0.222920   \n",
       " 52   0.244236  0.764611  0.660449    0.033232  0.073359      0.073297   \n",
       " 32   0.039588  0.655048  0.907665    0.021673  0.017766      0.230785   \n",
       " 111  0.480032  0.550521  0.567585    0.144646  0.045026      0.241220   \n",
       " 189  0.397292  0.436161  0.444079    0.165516  0.079562      0.327754   \n",
       " 106  0.314359  0.412930  0.865846    0.000000  0.016004      0.125725   \n",
       " 160  0.323789  0.479228  0.487523    0.111093  0.259974      0.045415   \n",
       " 114  0.673895  0.561098  0.545517    0.112538  0.067769      0.253549   \n",
       " 18   0.749921  0.578412  0.359221    0.142559  0.386553      0.150411   \n",
       " 134  0.423446  0.676406  0.350280    0.107401  0.224519      0.021703   \n",
       " ..        ...       ...       ...         ...       ...           ...   \n",
       " 10   0.437760  0.804260  0.515200    0.089742  0.089823      0.020607   \n",
       " 97   0.555432  0.558564  0.280297    0.324932  0.181407      0.085328   \n",
       " 93   0.292203  0.492052  0.509144    0.059400  0.281721      0.121098   \n",
       " 60   0.461550  0.416691  0.695481    0.038208  0.050770      0.276287   \n",
       " 159  0.302387  0.404703  0.455580    0.121689  0.182709      0.074726   \n",
       " 118  0.619918  0.322530  0.673779    0.043025  0.033081      0.695426   \n",
       " 132  0.486253  0.585747  0.607494    0.048804  0.015009      0.047089   \n",
       " 120  0.561845  0.437631  0.662521    0.083320  0.077724      0.770695   \n",
       " 149  0.661483  0.802475  0.266114    0.409697  0.439620      0.946334   \n",
       " 98   0.453018  0.464571  0.284158    0.365067  0.244199      0.078410   \n",
       " 112  0.424163  0.588842  0.522799    0.209022  0.080251      0.243231   \n",
       " 121  0.548278  0.326287  0.760993    0.068069  0.029482      0.230968   \n",
       " 194  0.503673  0.358856  0.518898    0.109327  0.050080      0.322794   \n",
       " 16   0.374227  0.280511  0.564578    0.068711  0.103760      0.504433   \n",
       " 17   0.704746  0.124041  0.485044    0.104190  0.207596      0.265442   \n",
       " 161  0.453594  0.438599  0.444891    0.136940  0.169385      0.068573   \n",
       " 155  0.452122  0.309726  0.568561    0.138546  0.128877      0.051449   \n",
       " 46   0.431002  0.228564  0.656791    0.028255  0.032927      0.326495   \n",
       " 49   0.280769  0.716282  0.671787    0.027131  0.052148      0.056960   \n",
       " 168  0.649132  0.601316  0.440055    0.203243  0.055134      0.235733   \n",
       " 53   0.356085  0.842338  0.690401    0.046717  0.094035      0.077002   \n",
       " 71   0.542287  0.633252  0.411648    0.224274  0.231028      0.151974   \n",
       " 35   0.455444  0.671119  0.946558    0.017659  0.018225      0.221317   \n",
       " 55   0.263058  0.946436  0.500935    0.158773  0.132859      0.049426   \n",
       " 133  0.272053  0.592870  0.698122    0.048162  0.014090      0.044047   \n",
       " 96   0.467088  0.474678  0.577989    0.053139  0.160043      0.136293   \n",
       " 166  0.190899  0.208872  0.659920    0.050570  0.012482      0.288974   \n",
       " 158  0.653514  0.211369  0.532106    0.252689  0.110116      0.106431   \n",
       " 151  0.736669  0.773041  0.000000    0.834323  1.000000      0.249618   \n",
       " 0    0.390661  0.960148  0.511745    0.145288  0.172448      0.112592   \n",
       " \n",
       "      MDVP:Flo(Hz)  MDVP:Fo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)    ...     \\\n",
       " 178      0.423239     0.351961        0.044790          0.051383    ...      \n",
       " 89       0.457137     0.531973        0.171855          0.130435    ...      \n",
       " 126      0.090032     0.289989        0.119441          0.130435    ...      \n",
       " 8        0.151289     0.043063        0.121665          0.209486    ...      \n",
       " 193      0.054279     0.642893        0.181703          0.130435    ...      \n",
       " 174      0.198320     0.166913        0.058767          0.090909    ...      \n",
       " 186      0.119474     0.164305        0.104193          0.130435    ...      \n",
       " 92       0.442289     0.348945        0.092440          0.090909    ...      \n",
       " 37       0.564717     0.511358        0.063850          0.051383    ...      \n",
       " 47       0.675383     0.955464        0.005400          0.000000    ...      \n",
       " 75       0.227590     0.130254        0.110546          0.169960    ...      \n",
       " 135      0.230739     0.128775        0.103558          0.130435    ...      \n",
       " 73       0.239202     0.137863        0.115947          0.169960    ...      \n",
       " 177      0.370669     0.369117        0.046379          0.051383    ...      \n",
       " 127      0.080809     0.457321        0.149301          0.130435    ...      \n",
       " 147      0.551913     0.554147        0.412325          0.288538    ...      \n",
       " 84       0.056813     0.515363        0.183926          0.130435    ...      \n",
       " 81       0.127080     0.042335        0.169632          0.249012    ...      \n",
       " 59       0.225707     0.154356        0.222046          0.288538    ...      \n",
       " 42       0.919727     0.866806        0.041296          0.011858    ...      \n",
       " 88       0.052972     0.498131        0.088945          0.090909    ...      \n",
       " 52       0.325883     0.230934        0.085133          0.090909    ...      \n",
       " 32       0.734786     0.640675        0.013977          0.011858    ...      \n",
       " 111      0.768846     0.699683        0.140089          0.090909    ...      \n",
       " 189      0.073416     0.660416        0.167090          0.090909    ...      \n",
       " 106      0.452934     0.388567        0.000000          0.011858    ...      \n",
       " 160      0.066473     0.150810        0.131194          0.169960    ...      \n",
       " 114      0.152820     0.686922        0.103875          0.051383    ...      \n",
       " 18       0.018118     0.376738        0.182338          0.169960    ...      \n",
       " 134      0.159067     0.105855        0.133736          0.209486    ...      \n",
       " ..            ...          ...             ...               ...    ...      \n",
       " 10       0.107062     0.000000        0.107052          0.209486    ...      \n",
       " 97       0.291956     0.213673        0.353240          0.367589    ...      \n",
       " 93       0.064021     0.371376        0.067980          0.090909    ...      \n",
       " 60       0.252761     0.703322        0.036213          0.011858    ...      \n",
       " 159      0.268846     0.230521        0.138818          0.169960    ...      \n",
       " 118      0.095496     0.523671        0.093393          0.090909    ...      \n",
       " 132      0.122739     0.178859        0.056544          0.090909    ...      \n",
       " 120      0.131121     0.236401        0.131194          0.169960    ...      \n",
       " 149      0.643557     0.665411        0.463469          0.288538    ...      \n",
       " 98       0.176920     0.218068        0.384371          0.407115    ...      \n",
       " 112      0.714734     0.677241        0.213787          0.130435    ...      \n",
       " 121      0.106423     0.515165        0.092757          0.090909    ...      \n",
       " 194      0.071948     0.733274        0.126747          0.090909    ...      \n",
       " 16       0.099531     0.325169        0.119441          0.130435    ...      \n",
       " 17       0.058304     0.468324        0.174714          0.130435    ...      \n",
       " 161      0.243681     0.157121        0.143266          0.169960    ...      \n",
       " 155      0.173742     0.171955        0.152160          0.169960    ...      \n",
       " 46       0.957845     0.915033        0.021283          0.011858    ...      \n",
       " 49       0.283257     0.201610        0.082592          0.090909    ...      \n",
       " 168      0.145762     0.635936        0.201715          0.130435    ...      \n",
       " 53       0.305871     0.238706        0.102287          0.130435    ...      \n",
       " 71       0.001577     0.279586        0.255083          0.249012    ...      \n",
       " 35       0.749778     0.658611        0.009530          0.011858    ...      \n",
       " 55       0.224308     0.125323        0.224269          0.288538    ...      \n",
       " 133      0.255392     0.177060        0.051779          0.090909    ...      \n",
       " 96       0.456752     0.412075        0.055273          0.051383    ...      \n",
       " 166      0.942923     0.867371        0.042884          0.011858    ...      \n",
       " 158      0.184618     0.220123        0.256353          0.288538    ...      \n",
       " 151      0.594822     0.608277        0.933609          0.604743    ...      \n",
       " 0        0.054815     0.184308        0.195680          0.249012    ...      \n",
       " \n",
       "      MDVP:Shimmer(dB)       NHR       PPE      RPDE  Shimmer:APQ3  \\\n",
       " 178          0.046836  0.013464  0.239769  0.340708      0.073960   \n",
       " 89           0.293344  0.227838  0.595547  0.780205      0.354777   \n",
       " 126          0.132293  0.055034  0.351131  0.855472      0.198190   \n",
       " 8            0.087099  0.031989  0.387368  0.837604      0.119029   \n",
       " 193          0.128184  0.227838  0.163137  0.454176      0.156009   \n",
       " 174          0.049302  0.016711  0.245593  0.305455      0.082049   \n",
       " 186          0.056697  0.042397  0.157543  0.722977      0.070300   \n",
       " 92           0.244864  0.058853  0.293997  0.461696      0.371341   \n",
       " 37           0.068200  0.008753  0.266511  0.198014      0.093028   \n",
       " 47           0.014790  0.011682  0.086695  0.825508      0.030624   \n",
       " 75           0.099425  0.012955  0.381264  0.482859      0.159669   \n",
       " 135          0.241578  0.078429  0.380632  0.925979      0.341680   \n",
       " 73           0.115859  0.017761  0.374713  0.589287      0.176810   \n",
       " 177          0.038620  0.016074  0.182599  0.326753      0.052581   \n",
       " 127          0.141331  0.055098  0.314804  0.766714      0.210324   \n",
       " 147          0.437962  0.190725  0.603830  0.516714      0.464176   \n",
       " 84           0.287592  0.172041  0.409214  0.699807      0.428351   \n",
       " 81           0.173377  0.056021  0.447559  0.745516      0.257512   \n",
       " 59           0.217749  0.034313  0.563049  0.679930      0.260015   \n",
       " 42           0.064914  0.021485  0.104578  0.113145      0.111710   \n",
       " 88           0.464256  0.132062  0.309661  0.799851      0.641949   \n",
       " 52           0.102712  0.013241  0.154856  0.474113      0.167180   \n",
       " 32           0.021364  0.001719  0.107245  0.488533      0.035632   \n",
       " 111          0.057518  0.024350  0.190235  0.190225      0.095724   \n",
       " 189          0.139688  0.139288  0.141456  0.587775      0.192411   \n",
       " 106          0.009860  0.005347  0.128955  0.181065      0.012904   \n",
       " 160          0.263763  0.063914  0.415073  0.925307      0.216487   \n",
       " 114          0.101890  0.031289  0.147001  0.174851      0.125578   \n",
       " 18           0.375514  0.098514  0.689459  0.953724      0.388290   \n",
       " 134          0.292523  0.094407  0.411204  0.889549      0.429122   \n",
       " ..                ...       ...       ...       ...           ...   \n",
       " 10           0.092030  0.035045  0.424998  0.827305      0.120185   \n",
       " 97           0.211175  0.257377  0.613229  0.870323      0.323575   \n",
       " 93           0.453574  0.036477  0.240810  0.445391      0.555855   \n",
       " 60           0.069844  0.025655  0.118007  0.198838      0.100154   \n",
       " 159          0.208710  0.082694  0.356440  0.929521      0.174307   \n",
       " 118          0.036154  0.025177  0.429621  0.498977      0.031202   \n",
       " 132          0.017256  0.026673  0.388689  0.500260      0.034284   \n",
       " 120          0.111750  0.072731  0.223452  0.539422      0.075886   \n",
       " 149          0.614626  0.249037  0.467318  0.399124      0.589368   \n",
       " 98           0.276910  0.326511  0.447025  0.733677      0.401965   \n",
       " 112          0.102712  0.039819  0.463115  0.565370      0.158320   \n",
       " 121          0.026294  0.034886  0.394074  0.334868      0.015216   \n",
       " 194          0.086278  0.137919  0.215460  0.481200      0.109977   \n",
       " 16           0.087921  0.057103  0.359600  0.725207      0.098998   \n",
       " 17           0.216105  0.090843  0.799972  0.873881      0.189908   \n",
       " 161          0.197206  0.087373  0.401265  0.749525      0.229006   \n",
       " 155          0.156943  0.081676  0.334937  0.867351      0.231895   \n",
       " 46           0.046015  0.013082  0.109349  0.492133      0.086864   \n",
       " 49           0.056697  0.012636  0.174665  0.658261      0.091487   \n",
       " 168          0.085456  0.040488  0.327943  0.269849      0.158706   \n",
       " 53           0.117502  0.013337  0.213227  0.382222      0.181240   \n",
       " 71           0.327034  0.104911  0.410999  0.669019      0.441834   \n",
       " 35           0.018077  0.002228  0.027072  0.204587      0.025231   \n",
       " 55           0.182416  0.035490  0.621950  0.704688      0.256934   \n",
       " 133          0.011504  0.013973  0.200657  0.526682      0.006741   \n",
       " 96           0.182416  0.025050  0.221963  0.256099      0.260208   \n",
       " 166          0.025472  0.014896  0.097478  0.299355      0.046418   \n",
       " 158          0.148726  0.119776  0.424922  0.883019      0.201271   \n",
       " 151          1.000000  0.689054  1.000000  0.861671      1.000000   \n",
       " 0            0.280197  0.068307  0.497310  0.369155      0.332627   \n",
       " \n",
       "      Shimmer:APQ5  Shimmer:DDA  const   spread1   spread2  \n",
       " 178      0.052374     0.074079    1.0  0.298863  0.396617  \n",
       " 89       0.298236     0.354859    1.0  0.648274  0.831250  \n",
       " 126      0.167571     0.198164    1.0  0.438375  0.182097  \n",
       " 8        0.095929     0.119014    1.0  0.445910  0.723731  \n",
       " 193      0.101900     0.155989    1.0  0.220650  0.452885  \n",
       " 174      0.066757     0.082103    1.0  0.353000  0.502059  \n",
       " 186      0.054545     0.070356    1.0  0.277324  0.330999  \n",
       " 92       0.264722     0.371421    1.0  0.363938  0.183617  \n",
       " 37       0.080054     0.093080    1.0  0.354111  0.427935  \n",
       " 47       0.021710     0.030620    1.0  0.116702  0.438070  \n",
       " 75       0.088060     0.159648    1.0  0.449722  0.695153  \n",
       " 135      0.274355     0.341764    1.0  0.475753  0.710843  \n",
       " 73       0.109227     0.176916    1.0  0.465716  0.676157  \n",
       " 177      0.042877     0.052638    1.0  0.267253  0.431420  \n",
       " 127      0.174898     0.210361    1.0  0.386864  0.246327  \n",
       " 147      0.479104     0.464180    1.0  0.666861  0.786689  \n",
       " 84       0.332700     0.428361    1.0  0.483836  0.758182  \n",
       " 81       0.172456     0.257607    1.0  0.512200  0.459647  \n",
       " 59       0.190502     0.259982    1.0  0.606735  0.484979  \n",
       " 42       0.061601     0.111696    1.0  0.118322  0.207947  \n",
       " 88       0.499864     0.641867    1.0  0.394455  0.660753  \n",
       " 52       0.068114     0.167223    1.0  0.161376  0.482105  \n",
       " 32       0.034600     0.035627    1.0  0.162188  0.380234  \n",
       " 111      0.066214     0.095712    1.0  0.270036  0.400937  \n",
       " 189      0.137313     0.192515    1.0  0.186317  0.345811  \n",
       " 106      0.008412     0.013031    1.0  0.177869  0.401325  \n",
       " 160      0.193216     0.216459    1.0  0.502445  0.569438  \n",
       " 114      0.096879     0.125562    1.0  0.223338  0.394911  \n",
       " 18       0.407327     0.388304    1.0  0.726078  0.791492  \n",
       " 134      0.344912     0.429195    1.0  0.481592  0.707108  \n",
       " ..            ...          ...    ...       ...       ...  \n",
       " 10       0.104749     0.120234    1.0  0.490913  0.866077  \n",
       " 97       0.217639     0.323662    1.0  0.713248  0.583138  \n",
       " 93       0.437449     0.555912    1.0  0.327689  0.376494  \n",
       " 60       0.093351     0.100205    1.0  0.167146  0.136689  \n",
       " 159      0.146540     0.174284    1.0  0.445950  0.513085  \n",
       " 118      0.023609     0.031262    1.0  0.551776  0.870701  \n",
       " 132      0.017775     0.034279    1.0  0.457218  0.559713  \n",
       " 120      0.074220     0.076005    1.0  0.321618  0.616045  \n",
       " 149      0.501357     0.589421    1.0  0.555508  0.576308  \n",
       " 98       0.279512     0.401913    1.0  0.507293  0.440936  \n",
       " 112      0.123881     0.158364    1.0  0.558430  0.463240  \n",
       " 121      0.008141     0.015342    1.0  0.588321  0.619838  \n",
       " 194      0.080190     0.110027    1.0  0.405161  0.415095  \n",
       " 16       0.085482     0.099114    1.0  0.456512  0.525619  \n",
       " 17       0.179512     0.189883    1.0  0.910135  0.963606  \n",
       " 161      0.156309     0.229105    1.0  0.484903  0.495823  \n",
       " 155      0.167436     0.231930    1.0  0.792135  0.453920  \n",
       " 46       0.055224     0.086982    1.0  0.146251  0.273217  \n",
       " 49       0.031479     0.091475    1.0  0.268107  0.582355  \n",
       " 168      0.095251     0.158685    1.0  0.402861  0.356254  \n",
       " 53       0.088060     0.181281    1.0  0.203974  0.593383  \n",
       " 71       0.257259     0.441841    1.0  0.498467  0.492050  \n",
       " 35       0.025780     0.025292    1.0  0.033864  0.368982  \n",
       " 55       0.192944     0.257029    1.0  0.656567  0.485015  \n",
       " 133      0.006920     0.006869    1.0  0.274247  0.388185  \n",
       " 96       0.197286     0.260175    1.0  0.279797  0.424009  \n",
       " 166      0.024016     0.046540    1.0  0.171205  0.382789  \n",
       " 158      0.137178     0.201245    1.0  0.523398  0.616401  \n",
       " 151      1.000000     1.000000    1.0  1.000000  1.000000  \n",
       " 0        0.347354     0.332584    1.0  0.569875  0.585765  \n",
       " \n",
       " [175 rows x 23 columns])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_y.head(10))\n",
    "print(train_x.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축 및 학습\n",
    "# statsmodels의 logit함수를 이용하여 모델을 적합해보자\n",
    "'''\n",
    "model = '_________'(train_y, train_x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a3c088d2ec7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 모델을 실제로 적합해보자\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델을 실제로 적합해보자\n",
    "'''\n",
    "results = model.____(method='bfgs')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AIC:  28.00189\n",
      "model BIC:  66.67233\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Y</td>        <th>  No. Observations:  </th>   <td>   117</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>   103</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>    13</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 13 Jan 2019</td> <th>  Pseudo R-squ.:     </th>   <td> 1.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>22:25:41</td>     <th>  Log-Likelihood:    </th> <td>-0.00094735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -80.580</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>1.148e-27</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1</th>    <td> -131.3890</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th>   <td>  -77.3007</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V11</th>   <td>   87.8636</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V12</th>   <td>   -9.8595</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V13</th>   <td> -172.4788</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V2</th>    <td>  -33.9721</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>    <td> -117.7264</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4</th>    <td>   96.9049</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5</th>    <td>  -40.2736</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6</th>    <td>    7.6310</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V7</th>    <td>  -35.6265</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V8</th>    <td>   38.1382</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V9</th>    <td>   36.9072</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  161.2942</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.98 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   No. Observations:                  117\n",
       "Model:                          Logit   Df Residuals:                      103\n",
       "Method:                           MLE   Df Model:                           13\n",
       "Date:                Sun, 13 Jan 2019   Pseudo R-squ.:                   1.000\n",
       "Time:                        22:25:41   Log-Likelihood:            -0.00094735\n",
       "converged:                       True   LL-Null:                       -80.580\n",
       "                                        LLR p-value:                 1.148e-27\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "V1          -131.3890        nan        nan        nan         nan         nan\n",
       "V10          -77.3007        nan        nan        nan         nan         nan\n",
       "V11           87.8636        nan        nan        nan         nan         nan\n",
       "V12           -9.8595        nan        nan        nan         nan         nan\n",
       "V13         -172.4788        nan        nan        nan         nan         nan\n",
       "V2           -33.9721        nan        nan        nan         nan         nan\n",
       "V3          -117.7264        nan        nan        nan         nan         nan\n",
       "V4            96.9049        nan        nan        nan         nan         nan\n",
       "V5           -40.2736        nan        nan        nan         nan         nan\n",
       "V6             7.6310        nan        nan        nan         nan         nan\n",
       "V7           -35.6265        nan        nan        nan         nan         nan\n",
       "V8            38.1382        nan        nan        nan         nan         nan\n",
       "V9            36.9072        nan        nan        nan         nan         nan\n",
       "const        161.2942        nan        nan        nan         nan         nan\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.98 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance measure\n",
    "print(\"model AIC: \",\"{:.5f}\".format(results.aic))\n",
    "print(\"model BIC: \",\"{:.5f}\".format(results.bic))\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23     9.988729e-44\n",
      "129    1.000000e+00\n",
      "82     1.000000e+00\n",
      "92     1.000000e+00\n",
      "118    1.000000e+00\n",
      "68     1.000000e+00\n",
      "96     1.000000e+00\n",
      "123    1.000000e+00\n",
      "0      2.666831e-39\n",
      "10     2.598862e-23\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 실제 Train 학습의 예측값을 출력해보자.\n",
    "'''\n",
    "train_y_pred = results.'______'(train_x)\n",
    "print(train_y_pred.head(10))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83     1.000000e+00\n",
      "84     1.000000e+00\n",
      "31     2.497188e-84\n",
      "111    1.000000e+00\n",
      "43     1.173782e-49\n",
      "105    1.000000e+00\n",
      "57     3.905277e-49\n",
      "108    1.000000e+00\n",
      "71     1.000000e+00\n",
      "26     1.524508e-62\n",
      "7      1.302212e-13\n",
      "85     1.000000e+00\n",
      "45     1.699351e-49\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 실제 Test데이터의 예측값을 출력해보자.\n",
    "'''\n",
    "test_y_pred = results.'_____'(test_x)\n",
    "print(test_y_pred.head(20))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cut-off 정의\n",
    "def cut_off(y,threshold):\n",
    "    Y = y.copy() # copy함수를 사용하여 이전의 y값이 변화지 않게 함\n",
    "    Y[Y>threshold]=1\n",
    "    Y[Y<=threshold]=0\n",
    "    return(Y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23     0\n",
      "129    1\n",
      "82     1\n",
      "92     1\n",
      "118    1\n",
      "68     1\n",
      "96     1\n",
      "123    1\n",
      "0      0\n",
      "10     0\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "train_y_pred_prob = results.predict(train_x)\n",
    "train_y_pred = cut_off(train_y_pred_prob,0.5)\n",
    "print( train_y_pred.head(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83     1\n",
      "84     1\n",
      "31     0\n",
      "111    1\n",
      "43     0\n",
      "105    1\n",
      "57     0\n",
      "108    1\n",
      "71     1\n",
      "26     0\n",
      "7      0\n",
      "85     1\n",
      "45     0\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "test_y_pred_prob = results.predict(test_x)\n",
    "test_y_pred = cut_off(test_y_pred_prob,0.5)\n",
    "print( test_y_pred.head(20) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83     1\n",
      "84     1\n",
      "31     0\n",
      "111    1\n",
      "43     0\n",
      "105    1\n",
      "57     0\n",
      "108    1\n",
      "71     1\n",
      "26     0\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "test_y_pred_prob = results.predict(test_x)\n",
    "test_y_pred = cut_off(test_y_pred_prob,0.5)\n",
    "print( test_y_pred.head(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  0]\n",
      " [ 0 64]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix: Training set\n",
    "cm_train = confusion_matrix(train_y,train_y_pred)\n",
    "print( cm_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0]\n",
      " [0 7]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix: Test set\n",
    "cm_test = confusion_matrix(test_y,test_y_pred)\n",
    "print( cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performance evaluation\n",
    "def perf_eval(cm):\n",
    "    # True positive rate: TPR\n",
    "    TPR = cm[1, 1] / sum(cm[1]) # recall\n",
    "    # True negative rate: TNR\n",
    "    TNR = cm[0, 0] / sum(cm[0])\n",
    "    # Simple Accuracy\n",
    "    ACC = (cm[0, 0] + cm[1, 1]) / sum(cm.reshape(-1,))\n",
    "    # Balanced Correction Rate\n",
    "    BCR = np.sqrt(TPR * TNR)\n",
    "    # F1-measure\n",
    "    Precision = cm[1,1] /sum(cm[:,1])\n",
    "    F1 = 2*TPR*Precision/(TPR+Precision)\n",
    "    return ([TPR, TNR, ACC, BCR, F1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance of Logistic Regression\n",
      "TPR: 1.0\n",
      "TNR: 1.0\n",
      "ACC: 1.0\n",
      "BCR: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Test performance of Logistic Regression')\n",
    "print('TPR:',perf_eval(cm_test)[0])\n",
    "print('TNR:',perf_eval(cm_test)[1])\n",
    "print('ACC:',perf_eval(cm_test)[2])\n",
    "print('BCR:',perf_eval(cm_test)[3])\n",
    "print('F1:',perf_eval(cm_test)[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임계값에 따른 비교\n",
    "threshold = np.arange(0, 1, 0.1)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [TPR, TNR, ACC, BCR, F1]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame(columns=['TPR','TNR','ACC','BCR','F1'])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in threshold:\n",
    "    test_y_pred_tmp = cut_off(test_y_pred_prob,i)\n",
    "    cfmat = confusion_matrix(test_y, test_y_pred_tmp)\n",
    "    table.loc[i] = perf_eval(cfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance  TPR  TNR       ACC  BCR   F1\n",
      "threshold                                \n",
      "0.0          1.0  0.0  0.538462  0.0  0.7\n",
      "0.1          1.0  1.0  1.000000  1.0  1.0\n",
      "0.2          1.0  1.0  1.000000  1.0  1.0\n",
      "0.3          1.0  1.0  1.000000  1.0  1.0\n",
      "0.4          1.0  1.0  1.000000  1.0  1.0\n",
      "0.5          1.0  1.0  1.000000  1.0  1.0\n",
      "0.6          1.0  1.0  1.000000  1.0  1.0\n",
      "0.7          1.0  1.0  1.000000  1.0  1.0\n",
      "0.8          1.0  1.0  1.000000  1.0  1.0\n",
      "0.9          1.0  1.0  1.000000  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "table.index.name='threshold'\n",
    "table.columns.name='performance'\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung",
   "language": "python",
   "name": "samsung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
